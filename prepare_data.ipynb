{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intialising all the library and package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the HR and LR mage for preprocessing for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH_HR = \"./Train/HR/\"\n",
    "DATA_PATH_LR = \"./Train/LR/\"\n",
    "TEST_PATH = \"./Test/Set14/\"\n",
    "train_img_num = 100\n",
    "test_img_num = 14\n",
    "Random_Crop = 400\n",
    "Patch_size = 32\n",
    "label_size = 20\n",
    "conv_side = 6\n",
    "scale = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing the data, With upscaling the LR image and making small patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data():\n",
    "    names1 = os.listdir(DATA_PATH_HR)\n",
    "    names2 = os.listdir(DATA_PATH_LR)\n",
    "    \n",
    "    names1 = sorted(names1)\n",
    "    names2 = sorted(names2)\n",
    "    nums1 = names1.__len__()\n",
    "    nums2 = names2.__len__()\n",
    "\n",
    "    data = numpy.zeros((train_img_num * Random_Crop, 1, Patch_size, Patch_size), dtype=numpy.double)\n",
    "    label = numpy.zeros((train_img_num * Random_Crop, 1, label_size, label_size), dtype=numpy.double)\n",
    "\n",
    "    if nums2 < train_img_num:\n",
    "        print(\"training img is not enough\")\n",
    "\n",
    "    for i in range(train_img_num):\n",
    "        name1 = DATA_PATH_HR + names1[i]\n",
    "        name2 = DATA_PATH_LR + names2[i]\n",
    "        hr_img = cv2.imread(name1, cv2.IMREAD_COLOR)\n",
    "        lr_img = cv2.imread(name2, cv2.IMREAD_COLOR)\n",
    "        shape1 = hr_img.shape\n",
    "        shape2 = lr_img.shape\n",
    "\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        hr_img = hr_img[:, :, 0]\n",
    "        \n",
    "        lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        lr_img = lr_img[:, :, 0]\n",
    "\n",
    "        # two resize operation to produce training data and labels\n",
    "        #lr_img1 = cv2.resize(hr_img, (int(shape1[1] / scale), int(shape1[0] / scale)))\n",
    "        #print(lr_img.shape)\n",
    "        lr_img = cv2.resize(lr_img, (shape1[1], shape1[0]))\n",
    "\n",
    "        #print(lr_img.shape)\n",
    "        # produce Random_Crop random coordinate to crop training img\n",
    "        Points_x = numpy.random.randint(0, min(shape1[0], shape1[1]) - Patch_size, Random_Crop)\n",
    "        Points_y = numpy.random.randint(0, min(shape1[0], shape1[1]) - Patch_size, Random_Crop)\n",
    "\n",
    "        for j in range(Random_Crop):\n",
    "            lr_patch = lr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "            hr_patch = hr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "\n",
    "            lr_patch = lr_patch.astype(float) / 255.\n",
    "            hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "            data[i * Random_Crop + j, 0, :, :] = lr_patch\n",
    "            label[i * Random_Crop + j, 0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "            #cv2.imshow(\"lr\", lr_patch)\n",
    "            #cv2.imshow(\"hr\", hr_patch)\n",
    "            #cv2.waitKey(0)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the cropped data into h5 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hdf5(data, labels, output_filename):\n",
    "    \"\"\"\n",
    "    This function is used to save image data and its label(s) to hdf5 file.\n",
    "    output_file.h5,contain data and label\n",
    "    \"\"\"\n",
    "\n",
    "    x = data.astype(numpy.float32)\n",
    "    y = labels.astype(numpy.float32)\n",
    "\n",
    "    with h5py.File(output_filename, 'w') as h:\n",
    "        h.create_dataset('data', data=x, shape=x.shape)\n",
    "        h.create_dataset('label', data=y, shape=y.shape)\n",
    "        # h.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data, label = prepare_training_data()\n",
    "    write_hdf5(data, label, \"train.h5\")\n",
    "    # _, _a = read_training_data(\"train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
