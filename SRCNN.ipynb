{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据 \n",
    "import sys\n",
    "import os\n",
    "h_r_folder_name = 'image-dataset/h_r'\n",
    "l_r_folder_name = 'image-dataset/l_r'\n",
    "h_r_files_list = os.listdir(h_r_folder_name)\n",
    "l_r_files_list = os.listdir(l_r_folder_name)\n",
    "h_r_files_list = [h_r_folder_name+'/'+ x for x in h_r_files_list]\n",
    "l_r_files_list = [l_r_folder_name+'/'+ x for x in l_r_files_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示数据\n",
    "import numpy as np\n",
    "import cv2\n",
    "img_hr = cv2.imread(h_r_files_list[3])\n",
    "img_lr = cv2.imread(l_r_files_list[3])\n",
    "cv2.imshow('image',img_lr)\n",
    "cv2.imshow('image2',img_hr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tcbcr和RGB色彩转换\n",
    "img_lr = cv2.cvtColor(img_lr, cv2.COLOR_BGR2YCR_CB)\n",
    "img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2YCR_CB)\n",
    "cv2.imshow('image',img_lr)\n",
    "cv2.imshow('image2',img_hr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c00865e85d5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Final arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mno_of_files\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msubimg_for_length\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msubimg_for_height\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubimg_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubimg_height\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mno_of_files\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msubimg_for_length\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msubimg_for_height\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubimg_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubimg_height\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# 缩放低分辨率图片用bicubic\n",
    "# 转换到Ycbcr格式\n",
    "# 为了做到这些我们需要子样品对儿\n",
    "\n",
    "no_of_files = len(h_r_files_list)\n",
    "\n",
    "## 为了subsampling我们设置大小为80px*80px\n",
    "subimg_length = 32\n",
    "stride_length = 32\n",
    "stride_height = 32\n",
    "subimg_height = 32\n",
    "\n",
    "sample_img = cv2.imread(h_r_files_list[0])\n",
    "subimg_for_length = int(np.shape(sample_img)[0])/(subimg_length+stride_length)\n",
    "subimg_for_height = int(np.shape(sample_img)[1])/(subimg_height+stride_height)\n",
    "\n",
    "# Final arrays \n",
    "X = np.ndarray(shape = (no_of_files*subimg_for_length*subimg_for_height,subimg_length,subimg_height,3))\n",
    "Y = np.ndarray(shape = (no_of_files*subimg_for_length*subimg_for_height,subimg_length,subimg_height,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(no_of_files):\n",
    "    # 缩放图片\n",
    "    img_lr = cv2.imread(l_r_files_list[i])\n",
    "    img_lr_zoomed = cv2.resize(img_lr, None,fx=2,fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "    img_hr = cv2.imread(h_r_files_list[i])\n",
    "    # 转换为YCbCr\n",
    "    img_lr_zoomed = cv2.cvtColor(img_lr_zoomed, cv2.COLOR_BGR2YCR_CB)\n",
    "    img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2YCR_CB)\n",
    "    #img_lr_zoomed.resize(3,480,320)\n",
    "    #img_hr.resize(3,480,320)\n",
    "    # 制作subsamples\n",
    "    for j in range(subimg_for_length):\n",
    "        for k in range(subimg_for_height):\n",
    "            img_current_lr = img_lr_zoomed[j*(stride_length+ subimg_length):j*(stride_length+ subimg_length)+subimg_length,\n",
    "                                           k*(stride_height+ subimg_height):k*(stride_height+ subimg_height)+subimg_height,:]\n",
    "            img_current_hr = img_hr[j*(stride_length+ subimg_length):j*(stride_length+ subimg_length)+subimg_length,\n",
    "                                    k*(stride_height+ subimg_height):k*(stride_height+ subimg_height)+subimg_height,:]\n",
    "            X[i*subimg_for_height*subimg_for_length+j*subimg_for_height +k] = img_current_lr\n",
    "            Y[i*subimg_for_height*subimg_for_length+j*subimg_for_height +k] = img_current_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 有了子图片 现在做3层卷积 filter大小5,1,3\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "#from layer import ConvLayer\n",
    "#from tools.image_processing import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备Theano variables西亚诺变量给input和target\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.tensor4('targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = lasagne.layers.InputLayer(shape=(None, 3,None, None), input_var=input_var)\n",
    "network = lasagne.layers.Conv2DLayer(\n",
    "        network, num_filters=32,pad=2, filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "network = lasagne.layers.Conv2DLayer(\n",
    "        network, num_filters=32, filter_size=(1, 1),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "network = lasagne.layers.Conv2DLayer(\n",
    "        network,pad=1, num_filters=3, filter_size=(3, 3),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#创建一个损失表达for training, i.e., a scalar objective we want\n",
    "# to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.squared_error(prediction, target_var)\n",
    "loss = loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个损失表达for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个损失表达for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network,deterministic=True)\n",
    "test_loss = lasagne.objectives.squared_error(test_prediction,target_var)\n",
    "test_loss = test_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译一个函数表达一个训练步骤on a mini-batch通过升级dictionary并返回相应的training损失\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "# 编译第二个函数用来计算 验证损失&精度：\n",
    "val_fn = theano.function([input_var, target_var], [test_loss])\n",
    "# for true test set\n",
    "predict_fn = theano.function([input_var],[test_prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 改变数据shape\n",
    "no_of_imgs = int(np.shape(X)[0])\n",
    "#X.shape(no_of_imgs,3,subimg_length,subimg_height)\n",
    "X = np.reshape(X,(no_of_imgs,3,subimg_length,subimg_height))\n",
    "Y = np.reshape(Y,(no_of_imgs,3,subimg_length,subimg_height))\n",
    "np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "        # 每个epoch 都要full pass训练数据\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X, Y, 100, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        #val_err = 0\n",
    "        #val_acc = 0\n",
    "        #val_batches = 0\n",
    "        #for batch in iterate_minibatches(X, Y, 100, shuffle=False):\n",
    "        #    inputs, targets = batch\n",
    "        #    err, acc = val_fn(inputs, targets)\n",
    "        #    val_err += err\n",
    "        #    val_acc += acc\n",
    "        #    val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        #print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        #print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        #    val_acc / val_batches * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已经训练过CNN\n",
    "# 和bicubic比较 \n",
    "\n",
    "img_lr = cv2.imread(l_r_files_list[1],1)\n",
    "img_hr_bicubic = cv2.resize(img_lr, None,fx=2,fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('image2',img_hr_bicubic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lr = cv2.imread(l_r_files_list[1],1)\n",
    "img_hr_bicubic = cv2.resize(img_lr, None,fx=2,fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "img_length = int(np.shape(img_hr_bicubic)[0])\n",
    "img_height = int(np.shape(img_hr_bicubic)[1])\n",
    "img_hr_bicubic_ycbcr = cv2.cvtColor(img_hr_bicubic, cv2.COLOR_BGR2YCR_CB)\n",
    "#img_hr_srcnn = img_hr_bicubic_ycbcr\n",
    "img_hr_srcnn = predict_fn(img_hr_bicubic_ycbcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_hr_srcnn_correct_dim = np.reshape(img_hr_srcnn,(img_length,img_height,3))\n",
    "img_hr_srcnn_correct_dim_BGR = cv2.cvtColor(img_hr_srcnn_correct_dim, cv2.COLOR_YCR_CB2BGR)\n",
    "cv2.imshow('image2',img_hr_srcnn_correct_dim_BGR)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
